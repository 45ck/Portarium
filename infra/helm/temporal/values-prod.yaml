# Temporal Helm values — production environment
#
# 3+ replica HA, PostgreSQL persistence + advanced visibility, strict PDB,
# topology spread across AZs, resource limits matched to production load.
#
# Bead: bead-0388

server:
  replicaCount: 3

  image:
    repository: temporalio/server
    tag: "1.25.2"
    pullPolicy: IfNotPresent

  config:
    logLevel: warn
    numHistoryShards: 512

    persistence:
      defaultStore: postgres-default
      visibilityStore: postgres-visibility
      advancedVisibilityStore: postgres-visibility
      numHistoryShards: 512

      datastores:
        postgres-default:
          sql:
            pluginName: postgres12
            databaseName: temporal
            connectAddr: "$(TEMPORAL_DB_HOST):5432"
            connectProtocol: tcp
            user: temporal
            maxConns: 100
            maxIdleConns: 50
            maxConnLifetime: 30m
            tls:
              enabled: true
              caFile: /etc/temporal/ssl/ca.crt
              enableHostVerification: true

        postgres-visibility:
          sql:
            pluginName: postgres12
            databaseName: temporal_visibility
            connectAddr: "$(TEMPORAL_DB_HOST):5432"
            connectProtocol: tcp
            user: temporal
            maxConns: 50
            maxIdleConns: 25
            maxConnLifetime: 30m
            tls:
              enabled: true
              caFile: /etc/temporal/ssl/ca.crt
              enableHostVerification: true

  # Per-service replica counts for production HA
  frontend:
    replicaCount: 3
    service:
      type: ClusterIP
      port: 7233
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 2000m
        memory: 2Gi

  history:
    replicaCount: 3
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 4000m
        memory: 4Gi

  matching:
    replicaCount: 3
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 2000m
        memory: 1Gi

  worker:
    replicaCount: 2
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 1Gi

  # Pod Disruption Budget — require at least 2 replicas available at all times
  podDisruptionBudget:
    enabled: true
    minAvailable: 2

  # Spread replicas across availability zones
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          app.kubernetes.io/name: temporal

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: temporal
          topologyKey: kubernetes.io/hostname

  # Security hardening
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000

  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

web:
  enabled: true
  replicaCount: 2
  resources:
    requests:
      cpu: 200m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

admintools:
  enabled: false

cassandra:
  enabled: false

mysql:
  enabled: false

postgresql:
  enabled: false

elasticsearch:
  enabled: false

schema:
  setup:
    enabled: true
    backoffLimit: 100
  update:
    enabled: true
    backoffLimit: 100
