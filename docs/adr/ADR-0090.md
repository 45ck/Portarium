# ADR-0090: Workflow Durability Fault-Injection Testing

**Status**: Accepted
**Date**: 2026-02-22
**Bead**: bead-0399

## Context

Temporal provides workflow durability guarantees — a workflow that is
interrupted mid-execution (worker crash, DB restart, network partition)
should resume from its last successful activity. These guarantees only hold
if the application code correctly implements activity heartbeats and uses
Temporal's built-in retry/replay semantics.

Without continuous validation, it is easy to introduce code changes that:
- Forget to heartbeat long-running activities (causing phantom retries).
- Use non-deterministic code in workflow functions (breaking replay).
- Miss DB reconnection backoff (causing cascading failures after failover).

## Decision

Implement monthly automated fault-injection drills via GitHub Actions
(`fault-injection.yml`) against the **staging** cluster only.

### Three fault scenarios

| Scenario | Fault introduced | Success criterion |
|---|---|---|
| Pod kill | `kubectl delete pod --force` on a random worker during a running workflow | Workflow resumes and completes within 3 minutes |
| DB failover | `aws rds reboot-db-instance --force-failover` while workflow is in heartbeat loop | Workflow completes within 5 minutes after DB returns |
| Network partition | NetworkPolicy drops worker→Temporal egress for 60 seconds | Workflow resumes within 5 minutes after policy removal |

### Sentinel workflow design

Each drill starts a `faultTestWorkflow` with four checkpointed steps:

1. `recordFaultTestStart` — write to evidence store (validates write-ahead log).
2. `heartbeatSleep` — heartbeat every 10 s for N seconds (the fault is
   introduced during this step).
3. `verifyDbConnectivity` — confirm DB is reachable post-fault.
4. `recordFaultTestCompletion` — final evidence write.

The workflow's activity functions are independently unit-tested without the
Temporal SDK, using dependency injection for the heartbeat function, sleep,
and query function.

### Safety guards

- The workflow `target_environment` input is validated; `prod` is explicitly
  rejected at the pre-flight job level.
- Network partition is implemented via a Kubernetes `NetworkPolicy` (not
  `iptables` or kernel-level tools) so it is reversible with a single
  `kubectl delete`.
- All fault experiments are self-cleaning (`if: always()` cleanup steps).

### Monitoring during drills

- The control-plane `/internal/fault-test/status/:id` endpoint is polled by
  the CI job to detect completion.
- SLO burn-rate alerts (ADR-0085) are watched during drills — if a real
  burn-rate spike occurs it indicates the fault affected live traffic, not
  just the sentinel workflow.

## Consequences

**Positive**
- Monthly drills provide continuous proof that Temporal's durability
  guarantees hold for Portarium's specific activity implementations.
- Unit-testable `faultTestWorkflow` code verifies heartbeat and retry
  semantics without requiring a running Temporal cluster.
- Network partition test uses Kubernetes-native tooling — no chaos engineering
  framework required.

**Negative / Trade-offs**
- Requires the staging cluster to be up and healthy when the drill runs
  (monthly cron). If staging is down, the drill skips (scheduled jobs
  fail silently on infrastructure unavailability).
- The `/internal/fault-test/start` and `/internal/fault-test/status`
  endpoints must be implemented in the control-plane and gated by an
  `INTERNAL_API_TOKEN` secret — this is an operational prerequisite.
- DB failover on staging means a ~30–60 second outage for staging users;
  acceptable for monthly frequency at 03:00 UTC.

## Related

- ADR-0085: SLO definitions (burn-rate monitoring during drills)
- ADR-0086: Progressive delivery (canary SLO-gated promotion)
- ADR-0088: DR drills (complementary recovery validation)
- bead-0388: Temporal deployment
